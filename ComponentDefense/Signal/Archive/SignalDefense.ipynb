{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import List, Union, Tuple\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ============================================================\n",
        "# PART 1: PHYSICS PRIMITIVES (The Trust Engine)\n",
        "# ============================================================\n",
        "\n",
        "class TrustGate(nn.Module):\n",
        "    \"\"\"\n",
        "    [The Safety Valve]\n",
        "    Bounded Precision Normalization.\n",
        "\n",
        "    Physics:\n",
        "    1. Splits Signal into Direction (Shape) and Amplitude (Loudness).\n",
        "    2. Calculates Trust Score = Amplitude / (Sigma + epsilon).\n",
        "    3. Bounds Gain using Tanh(Score).\n",
        "    4. Output = Direction * Trusted_Gain.\n",
        "\n",
        "    Result:\n",
        "    - High Amp / Low Sigma -> Gain ~ 1.0 (Trusted)\n",
        "    - High Amp / High Sigma -> Gain ~ 0.0 (Silenced)\n",
        "    \"\"\"\n",
        "    def __init__(self, sensitivity: float = 1.0, epsilon: float = 1e-6):\n",
        "        super().__init__()\n",
        "        self.sensitivity = sensitivity\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # x: (..., 5) -> [c3, c2, c1, c0, sigma]\n",
        "\n",
        "        # 1. Split Data\n",
        "        coeffs = x[..., :4]\n",
        "        sigma = x[..., 4:5]\n",
        "\n",
        "        # 2. Measure Amplitude (L2 Norm of coeffs)\n",
        "        # (..., 1)\n",
        "        amplitude = torch.norm(coeffs, p=2, dim=-1, keepdim=True)\n",
        "\n",
        "        # 3. Calculate Normalized Direction (Unit Sphere)\n",
        "        # Avoid div by zero for silent signals\n",
        "        direction = coeffs / (amplitude + self.epsilon)\n",
        "\n",
        "        # 4. Calculate Trust Score (The SNR)\n",
        "        # \"How much louder is the signal than the noise?\"\n",
        "        trust_score = amplitude / (sigma + self.epsilon)\n",
        "\n",
        "        # 5. Determine Bounded Gain (The Safety Tanh)\n",
        "        # Maps Score [0, inf] -> Gain [0, 1]\n",
        "        # If Score is high (e.g. 10), Tanh approaches 1.0.\n",
        "        # If Score is low (e.g. 0.5), Tanh drops.\n",
        "        trusted_gain = torch.tanh(trust_score * self.sensitivity)\n",
        "\n",
        "        # 6. Apply Gain to Direction\n",
        "        # The output magnitude is now strictly determined by Trust, not raw Amplitude.\n",
        "        out_coeffs = direction * trusted_gain\n",
        "\n",
        "        # Re-attach the sigma (it propagates to the next layer)\n",
        "        return torch.cat([out_coeffs, sigma], dim=-1)\n",
        "\n",
        "class Atom(nn.Module):\n",
        "    \"\"\"\n",
        "    [The Phoneme]\n",
        "    Resolution-Agnostic Warper with Trust Gating.\n",
        "\n",
        "    Processing:\n",
        "    1. Resamples Input (M) -> Internal (N).\n",
        "    2. Warps Coefficients (Interaction).\n",
        "    3. Resamples/Propagates Sigma.\n",
        "    4. Applies TrustGate to silence noisy outputs.\n",
        "    \"\"\"\n",
        "    def __init__(self, out_segments: int):\n",
        "        super().__init__()\n",
        "        self.out_segments = out_segments\n",
        "\n",
        "        # The Basis: A fixed template of N segments\n",
        "        self.basis = nn.Parameter(torch.randn(out_segments, 4))\n",
        "\n",
        "        # The Gate: Enforces precision at the output\n",
        "        self.gate = TrustGate(sensitivity=0.5)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # x: (B, T, M, 5) -> [Coeffs(4) | Sigma(1)]\n",
        "        B, T, M, C = x.shape\n",
        "        N = self.out_segments\n",
        "\n",
        "        # 1. Resample (Project M -> N)\n",
        "        # We process Coeffs and Sigma together\n",
        "        if M != N:\n",
        "            flat_x = x.view(B * T, M, C).transpose(1, 2) # (BT, 5, M)\n",
        "            # Linear interp for coeffs is valid.\n",
        "            # Linear interp for Sigma is a reasonable approximation for \"Smearing\" uncertainty.\n",
        "            resampled = F.interpolate(flat_x, size=N, mode='linear', align_corners=True)\n",
        "            current_stream = resampled.transpose(1, 2).view(B, T, N, C)\n",
        "        else:\n",
        "            current_stream = x\n",
        "\n",
        "        # Split\n",
        "        in_coeffs = current_stream[..., :4] # (B, T, N, 4)\n",
        "        in_sigma = current_stream[..., 4:5] # (B, T, N, 1)\n",
        "\n",
        "        # 2. Warp (Interaction)\n",
        "        # Modulate internal basis by the input signal\n",
        "        # This creates the new \"Shape\"\n",
        "        warped_coeffs = in_coeffs * self.basis\n",
        "\n",
        "        # 3. Propagate Uncertainty\n",
        "        # Basic heuristic: Warping implies scaling.\n",
        "        # If we scaled the coeffs, we technically scaled the error too.\n",
        "        # But TrustGate will handle the renormalization.\n",
        "        # We pass the resampled sigma through.\n",
        "\n",
        "        # Recombine\n",
        "        warped_stream = torch.cat([warped_coeffs, in_sigma], dim=-1)\n",
        "\n",
        "        # 4. Trust Gating\n",
        "        # If the Warp created a massive signal but the underlying Sigma was high,\n",
        "        # TrustGate will crush it back down.\n",
        "        return self.gate(warped_stream)\n",
        "\n",
        "# ============================================================\n",
        "# PART 2: GRAMMAR STRUCTURES\n",
        "# ============================================================\n",
        "\n",
        "class Compound(nn.Module):\n",
        "    \"\"\"\n",
        "    [The Phrase]\n",
        "    Recursive Container with Uncertainty Propagation.\n",
        "    \"\"\"\n",
        "    def __init__(self, dna_config):\n",
        "        super().__init__()\n",
        "        self.dna = dna_config\n",
        "\n",
        "        # Parse DNA\n",
        "        node_type, op_mode, content = dna_config\n",
        "        self.mode = node_type # \"SERIES\" or \"PARALLEL\"\n",
        "        self.op = op_mode     # \"SUM\", \"PRODUCT\", or None\n",
        "\n",
        "        self.branches = nn.ModuleList()\n",
        "\n",
        "        # Build Branches\n",
        "        for child_dna in content:\n",
        "            self.branches.append(build_node(child_dna))\n",
        "\n",
        "        # Global Gate for the Compound\n",
        "        self.gate = TrustGate()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 1. Execution\n",
        "        if self.mode == \"SERIES\":\n",
        "            results = x\n",
        "            for child in self.branches:\n",
        "                results = child(results)\n",
        "\n",
        "        elif self.mode == \"PARALLEL\":\n",
        "            # Run all branches\n",
        "            branch_outputs = [child(x) for child in self.branches]\n",
        "\n",
        "            # 2. Interaction\n",
        "            if self.op == \"SUM\":\n",
        "                # Bundling: Add Coefficients, Add Variances\n",
        "                # C_new = C1 + C2\n",
        "                # Sigma_new = sqrt(s1^2 + s2^2)\n",
        "\n",
        "                # Stack to sum easily\n",
        "                stack = torch.stack(branch_outputs, dim=0) # (Branches, B, T, N, 5)\n",
        "                coeffs = stack[..., :4].sum(dim=0)\n",
        "\n",
        "                # Variance summation\n",
        "                sigmas = stack[..., 4]\n",
        "                new_sigma = torch.sqrt((sigmas ** 2).sum(dim=0)).unsqueeze(-1)\n",
        "\n",
        "                results = torch.cat([coeffs, new_sigma], dim=-1)\n",
        "\n",
        "            elif self.op == \"PRODUCT\":\n",
        "                # Binding: Coeffs * Coeffs\n",
        "                # For PoC, we propagate Max Sigma (Conservative estimate)\n",
        "                # or we can do sqrt sum of squares for \"Fog of War\" approx\n",
        "\n",
        "                # Base\n",
        "                base = branch_outputs[0]\n",
        "                c_acc = base[..., :4]\n",
        "                s_acc_sq = base[..., 4] ** 2\n",
        "\n",
        "                for b in branch_outputs[1:]:\n",
        "                    c_next = b[..., :4]\n",
        "                    s_next = b[..., 4]\n",
        "\n",
        "                    c_acc = c_acc * c_next\n",
        "                    s_acc_sq = s_acc_sq + (s_next ** 2)\n",
        "\n",
        "                s_final = torch.sqrt(s_acc_sq).unsqueeze(-1)\n",
        "                results = torch.cat([c_acc, s_final], dim=-1)\n",
        "            else:\n",
        "                results = branch_outputs[0]\n",
        "\n",
        "        # 3. Regulation\n",
        "        return self.gate(results)\n",
        "\n",
        "def build_node(dna):\n",
        "    \"\"\"Factory: Converts DNA list into Objects\"\"\"\n",
        "    node_type, op, content = dna\n",
        "\n",
        "    if node_type == \"LEAF\":\n",
        "        return Atom(out_segments=content)\n",
        "    elif node_type in [\"SERIES\", \"PARALLEL\"]:\n",
        "        return Compound(dna)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown Node Type: {node_type}\")\n",
        "\n",
        "# ============================================================\n",
        "# PART 3: THE EYE (Retina with Residuals)\n",
        "# ============================================================\n",
        "\n",
        "class VisualRetina(nn.Module):\n",
        "    \"\"\"\n",
        "    [V10.9 Physics]\n",
        "    Converts Pixels -> Trustworthy Spline Stream.\n",
        "    Outputs: [c3, c2, c1, c0, RMSE]\n",
        "    \"\"\"\n",
        "    def __init__(self, window_size: int = 32):\n",
        "        super().__init__()\n",
        "        self.window_size = window_size\n",
        "        self.register_buffer('z_indices', self._precompute_z(window_size))\n",
        "\n",
        "    def _precompute_z(self, size):\n",
        "        y = torch.arange(size).repeat_interleave(size)\n",
        "        x = torch.arange(size).repeat(size)\n",
        "        z = torch.zeros_like(y)\n",
        "        for i in range(8):\n",
        "            z |= ((x & (1 << i)) << i) | ((y & (1 << i)) << (i + 1))\n",
        "        return torch.argsort(z)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # Input: (B, 3, H, W)\n",
        "        B, C, H, W = x.shape\n",
        "        x_resized = F.interpolate(x, size=(self.window_size, self.window_size))\n",
        "\n",
        "        # Z-Order Flatten\n",
        "        x_flat = x_resized.view(B, C, -1)\n",
        "        x_z = torch.gather(x_flat, 2, self.z_indices.unsqueeze(0).unsqueeze(0).expand(B, C, -1))\n",
        "\n",
        "        # Chunking\n",
        "        chunk_size = 16\n",
        "        num_chunks = x_z.shape[-1] // chunk_size\n",
        "        chunks = x_z.view(B, C, num_chunks, chunk_size)\n",
        "\n",
        "        # --- Fit Cubic (with RMSE) ---\n",
        "        t = torch.linspace(-1, 1, chunk_size, device=x.device)\n",
        "        T_mat = torch.stack([t**3, t**2, t, torch.ones_like(t)], dim=1) # (16, 4)\n",
        "        T_pinv = torch.linalg.pinv(T_mat) # (4, 16)\n",
        "\n",
        "        y = chunks.permute(0, 2, 3, 1) # (B, Chunks, 16, C)\n",
        "\n",
        "        # 1. Solve Coefficients\n",
        "        coeffs = torch.matmul(T_pinv, y) # (B, Chunks, 4, C)\n",
        "\n",
        "        # 2. Calculate Residuals (Sigma)\n",
        "        # Reconstruct y_pred\n",
        "        # T_mat (16, 4) @ coeffs (..., 4, C) -> (..., 16, C)\n",
        "        # We need to broadcast T_mat\n",
        "        y_pred = torch.matmul(T_mat, coeffs)\n",
        "\n",
        "        # MSE = mean((y - y_pred)^2)\n",
        "        residuals = (y - y_pred).pow(2).mean(dim=2) # Mean over chunk_len (16) -> (B, Chunks, C)\n",
        "        sigma = residuals.sqrt().unsqueeze(2) # (B, Chunks, 1, C)\n",
        "\n",
        "        # Combine [Coeffs(4), Sigma(1)] -> (B, Chunks, 5, C)\n",
        "        token_data = torch.cat([coeffs, sigma], dim=2)\n",
        "\n",
        "        # Structure Extraction (Mean over channels for PoC)\n",
        "        # (B, Chunks, 5)\n",
        "        structure = token_data.mean(dim=-1)\n",
        "\n",
        "        # Output: (B, Time, 1, 5)\n",
        "        return structure.unsqueeze(2)\n",
        "\n",
        "# ============================================================\n",
        "# PART 4: SYSTEM WRAPPER\n",
        "# ============================================================\n",
        "\n",
        "class VisionModule(nn.Module):\n",
        "    def __init__(self, topology_dna, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.retina = VisualRetina(window_size=32)\n",
        "        self.brain = build_node(topology_dna)\n",
        "\n",
        "        # Head input size: Segments * 5 (Coeffs+Sigma)\n",
        "        # We assume the user topology ends with a specific segment count\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.LazyLinear(num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        stream = self.retina(x)      # (B, T, 1, 5)\n",
        "        thought = self.brain(stream) # (B, T, N, 5)\n",
        "\n",
        "        # Flatten (B, T*N*5)\n",
        "        concept = thought.reshape(thought.shape[0], -1)\n",
        "        return self.head(concept)\n",
        "\n",
        "# ============================================================\n",
        "# PART 5: TRAINING\n",
        "# ============================================================\n",
        "\n",
        "class TrainingPlotter:\n",
        "    def __init__(self, save_path=\"training_metrics.png\"):\n",
        "        self.save_path = save_path\n",
        "        self.epochs = []\n",
        "        self.train_loss = []\n",
        "        self.train_acc = []\n",
        "\n",
        "    def update(self, epoch, t_loss, t_acc):\n",
        "        self.epochs.append(epoch)\n",
        "        self.train_loss.append(t_loss)\n",
        "        self.train_acc.append(t_acc)\n",
        "        self._plot()\n",
        "\n",
        "    def _plot(self):\n",
        "        fig, ax1 = plt.subplots(figsize=(8, 5))\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.set_ylabel('Loss', color='tab:red')\n",
        "        ax1.plot(self.epochs, self.train_loss, color='tab:red', linestyle='--', label='Train Loss')\n",
        "\n",
        "        ax2 = ax1.twinx()\n",
        "        ax2.set_ylabel('Accuracy (%)', color='tab:blue')\n",
        "        ax2.plot(self.epochs, self.train_acc, color='tab:blue', label='Train Acc')\n",
        "\n",
        "        plt.title('Vision V10.9 (Trust Architecture)')\n",
        "        fig.tight_layout()\n",
        "        plt.savefig(self.save_path)\n",
        "        plt.close()\n",
        "\n",
        "def train_vision_model(model, epochs=5, plotter=None):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"--- Device: {device} ---\")\n",
        "    model.to(device)\n",
        "\n",
        "    import torchvision\n",
        "    import torchvision.transforms as transforms\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=1e-3)\n",
        "\n",
        "    start_epoch = plotter.epochs[-1] + 1 if (plotter and plotter.epochs) else 1\n",
        "\n",
        "    print(f\"--- Starting Session: {epochs} Epochs ---\")\n",
        "    for epoch in range(epochs):\n",
        "        current_epoch = start_epoch + epoch\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        pbar = tqdm(trainloader, desc=f\"Ep {current_epoch}\", unit=\"batch\")\n",
        "        for i, (inputs, labels) in enumerate(pbar):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            # Diagnostic\n",
        "            if epoch == 0 and i == 0:\n",
        "                with torch.no_grad():\n",
        "                    dummy_out = model.retina(inputs)\n",
        "                    print(f\"\\n[DEBUG] Retina Out: {dummy_out.shape} (Includes Sigma)\")\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            pbar.set_postfix(loss=loss.item(), acc=f\"{100*correct/total:.2f}%\")\n",
        "\n",
        "        avg_loss = running_loss / len(trainloader)\n",
        "        acc = 100 * correct / total\n",
        "        if plotter: plotter.update(current_epoch, avg_loss, acc)\n",
        "\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # --- TOPOLOGY MACRO (5-Channel DNA) ---\n",
        "    # Note: Removed \"Phi Mode\" from DNA since TrustGate is standard now.\n",
        "    # Format: [TYPE, OP, CONTENT]\n",
        "\n",
        "    attention_block = [\n",
        "        \"PARALLEL\", \"PRODUCT\", [ # Binding\n",
        "            [\n",
        "                \"PARALLEL\", \"PRODUCT\", [ # Interaction\n",
        "                    [\"LEAF\", None, 64], # Q\n",
        "                    [\"LEAF\", None, 64]  # K\n",
        "                ]\n",
        "            ],\n",
        "            [\"LEAF\", None, 64] # V\n",
        "        ]\n",
        "    ]\n",
        "\n",
        "    model_topo = [\n",
        "        \"SERIES\", None, [\n",
        "            attention_block,\n",
        "            attention_block,\n",
        "            attention_block,\n",
        "            [\"LEAF\", None, 64] # Final Output\n",
        "        ]\n",
        "    ]\n",
        "\n",
        "    print(\"Initializing Vision V10.9 (Trust Architecture)...\")\n",
        "    model = VisionModule(model_topo)\n",
        "    plotter = TrainingPlotter()\n",
        "\n",
        "    model = train_vision_model(model, epochs=5, plotter=plotter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fqm-r6_YVYvz",
        "outputId": "c697ebdc-6765-47e5-9486-9b631fdf4d72"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Vision V10.9 (Trust Architecture)...\n",
            "--- Device: cuda ---\n",
            "--- Starting Session: 5 Epochs ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 1:   0%|          | 1/782 [00:00<02:02,  6.40batch/s, acc=7.81%, loss=2.33]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[DEBUG] Retina Out: torch.Size([64, 64, 1, 5]) (Includes Sigma)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 1: 100%|██████████| 782/782 [00:36<00:00, 21.67batch/s, acc=29.32%, loss=1.93]\n",
            "Ep 2: 100%|██████████| 782/782 [00:37<00:00, 21.00batch/s, acc=34.32%, loss=1.3]\n",
            "Ep 3: 100%|██████████| 782/782 [00:35<00:00, 21.87batch/s, acc=36.73%, loss=1.86]\n",
            "Ep 4: 100%|██████████| 782/782 [00:36<00:00, 21.71batch/s, acc=39.70%, loss=2.1]\n",
            "Ep 5: 100%|██████████| 782/782 [00:36<00:00, 21.54batch/s, acc=42.17%, loss=1.42]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_vision_model(model, epochs=10, plotter=plotter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-qmEV0IxkcS",
        "outputId": "c7b62277-0320-4844-d006-1d05c684dc29"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Device: cuda ---\n",
            "--- Starting Session: 10 Epochs ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEp 6:   0%|          | 0/782 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[DEBUG] Retina Out: torch.Size([64, 64, 1, 5]) (Includes Sigma)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 6: 100%|██████████| 782/782 [00:36<00:00, 21.44batch/s, acc=43.70%, loss=1.81]\n",
            "Ep 7: 100%|██████████| 782/782 [00:36<00:00, 21.38batch/s, acc=45.87%, loss=1.19]\n",
            "Ep 8: 100%|██████████| 782/782 [00:36<00:00, 21.37batch/s, acc=47.30%, loss=1.81]\n",
            "Ep 9: 100%|██████████| 782/782 [00:36<00:00, 21.59batch/s, acc=48.26%, loss=1.75]\n",
            "Ep 10: 100%|██████████| 782/782 [00:36<00:00, 21.59batch/s, acc=49.79%, loss=1.5]\n",
            "Ep 11: 100%|██████████| 782/782 [00:36<00:00, 21.52batch/s, acc=51.28%, loss=1.58]\n",
            "Ep 12: 100%|██████████| 782/782 [00:36<00:00, 21.35batch/s, acc=52.27%, loss=1.44]\n",
            "Ep 13: 100%|██████████| 782/782 [00:36<00:00, 21.34batch/s, acc=53.23%, loss=1.46]\n",
            "Ep 14: 100%|██████████| 782/782 [00:36<00:00, 21.61batch/s, acc=54.14%, loss=2.55]\n",
            "Ep 15: 100%|██████████| 782/782 [00:36<00:00, 21.55batch/s, acc=54.84%, loss=1.01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_vision_model(model, epochs=10, plotter=plotter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBDf38pwyPbN",
        "outputId": "d5e019fa-73bb-42bf-d4c8-d766ec56d5d5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Device: cuda ---\n",
            "--- Starting Session: 10 Epochs ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 16:   0%|          | 0/782 [00:00<?, ?batch/s, acc=54.69%, loss=1.22]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[DEBUG] Retina Out: torch.Size([64, 64, 1, 5]) (Includes Sigma)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 16: 100%|██████████| 782/782 [00:36<00:00, 21.42batch/s, acc=55.46%, loss=1.47]\n",
            "Ep 17: 100%|██████████| 782/782 [00:36<00:00, 21.53batch/s, acc=56.20%, loss=1.6]\n",
            "Ep 18: 100%|██████████| 782/782 [00:36<00:00, 21.60batch/s, acc=57.16%, loss=1.23]\n",
            "Ep 19: 100%|██████████| 782/782 [00:36<00:00, 21.56batch/s, acc=58.23%, loss=0.953]\n",
            "Ep 20: 100%|██████████| 782/782 [00:36<00:00, 21.31batch/s, acc=58.74%, loss=1.28]\n",
            "Ep 21: 100%|██████████| 782/782 [00:36<00:00, 21.52batch/s, acc=59.08%, loss=2.12]\n",
            "Ep 22: 100%|██████████| 782/782 [00:36<00:00, 21.48batch/s, acc=60.05%, loss=1.24]\n",
            "Ep 23: 100%|██████████| 782/782 [00:36<00:00, 21.47batch/s, acc=59.90%, loss=1.59]\n",
            "Ep 24: 100%|██████████| 782/782 [00:36<00:00, 21.62batch/s, acc=60.72%, loss=1]\n",
            "Ep 25: 100%|██████████| 782/782 [00:36<00:00, 21.52batch/s, acc=61.24%, loss=1.48]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_vision_model(model, epochs=10, plotter=plotter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ommw72yUy256",
        "outputId": "0ec7ffef-451a-4cd6-e7f6-935c4a5b2006"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Device: cuda ---\n",
            "--- Starting Session: 10 Epochs ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEp 26:   0%|          | 0/782 [00:00<?, ?batch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[DEBUG] Retina Out: torch.Size([64, 64, 1, 5]) (Includes Sigma)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 26: 100%|██████████| 782/782 [00:36<00:00, 21.64batch/s, acc=61.72%, loss=1.29]\n",
            "Ep 27: 100%|██████████| 782/782 [00:36<00:00, 21.57batch/s, acc=62.00%, loss=1.7]\n",
            "Ep 28: 100%|██████████| 782/782 [00:36<00:00, 21.42batch/s, acc=62.63%, loss=1.98]\n",
            "Ep 29: 100%|██████████| 782/782 [00:36<00:00, 21.54batch/s, acc=62.85%, loss=1.82]\n",
            "Ep 30: 100%|██████████| 782/782 [00:36<00:00, 21.65batch/s, acc=63.41%, loss=1.61]\n",
            "Ep 31: 100%|██████████| 782/782 [00:36<00:00, 21.63batch/s, acc=64.04%, loss=1.14]\n",
            "Ep 32: 100%|██████████| 782/782 [00:36<00:00, 21.54batch/s, acc=64.65%, loss=1.97]\n",
            "Ep 33: 100%|██████████| 782/782 [00:36<00:00, 21.58batch/s, acc=64.59%, loss=1.26]\n",
            "Ep 34: 100%|██████████| 782/782 [00:36<00:00, 21.68batch/s, acc=64.91%, loss=0.611]\n",
            "Ep 35: 100%|██████████| 782/782 [00:35<00:00, 21.73batch/s, acc=65.34%, loss=1.42]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_vision_model(model, epochs=10, plotter=plotter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIUXOQiq2-pA",
        "outputId": "75b43745-a1bd-4dde-b03d-ba9be6e32ef5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Device: cuda ---\n",
            "--- Starting Session: 10 Epochs ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 36:   0%|          | 1/782 [00:00<02:05,  6.24batch/s, acc=64.06%, loss=1.23]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[DEBUG] Retina Out: torch.Size([64, 64, 1, 5]) (Includes Sigma)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 36: 100%|██████████| 782/782 [00:36<00:00, 21.54batch/s, acc=65.10%, loss=1.49]\n",
            "Ep 37: 100%|██████████| 782/782 [00:37<00:00, 21.03batch/s, acc=66.03%, loss=1.01]\n",
            "Ep 38: 100%|██████████| 782/782 [00:36<00:00, 21.63batch/s, acc=66.46%, loss=1.08]\n",
            "Ep 39: 100%|██████████| 782/782 [00:36<00:00, 21.55batch/s, acc=66.52%, loss=1.42]\n",
            "Ep 40: 100%|██████████| 782/782 [00:36<00:00, 21.47batch/s, acc=66.88%, loss=0.943]\n",
            "Ep 41: 100%|██████████| 782/782 [00:36<00:00, 21.52batch/s, acc=67.24%, loss=1.53]\n",
            "Ep 42: 100%|██████████| 782/782 [00:36<00:00, 21.61batch/s, acc=67.61%, loss=1.79]\n",
            "Ep 43: 100%|██████████| 782/782 [00:36<00:00, 21.57batch/s, acc=67.51%, loss=1.18]\n",
            "Ep 44: 100%|██████████| 782/782 [00:36<00:00, 21.53batch/s, acc=68.09%, loss=1.4]\n",
            "Ep 45: 100%|██████████| 782/782 [00:36<00:00, 21.43batch/s, acc=68.19%, loss=0.599]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_vision_model(model, epochs=10, plotter=plotter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClrDCELk5ME1",
        "outputId": "1ceef92c-bde6-4c88-b1f7-a7e0806de616"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Device: cuda ---\n",
            "--- Starting Session: 10 Epochs ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 46:   0%|          | 1/782 [00:00<02:01,  6.45batch/s, acc=81.25%, loss=0.655]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[DEBUG] Retina Out: torch.Size([64, 64, 1, 5]) (Includes Sigma)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Ep 46: 100%|██████████| 782/782 [00:36<00:00, 21.46batch/s, acc=68.00%, loss=1.55]\n",
            "Ep 47: 100%|██████████| 782/782 [00:36<00:00, 21.47batch/s, acc=68.06%, loss=1.43]\n",
            "Ep 48: 100%|██████████| 782/782 [00:36<00:00, 21.52batch/s, acc=69.26%, loss=0.594]\n",
            "Ep 49: 100%|██████████| 782/782 [00:36<00:00, 21.45batch/s, acc=68.72%, loss=0.971]\n",
            "Ep 50: 100%|██████████| 782/782 [00:36<00:00, 21.48batch/s, acc=69.65%, loss=1.18]\n",
            "Ep 51: 100%|██████████| 782/782 [00:36<00:00, 21.52batch/s, acc=69.50%, loss=1.46]\n",
            "Ep 52: 100%|██████████| 782/782 [00:36<00:00, 21.51batch/s, acc=69.62%, loss=0.84]\n",
            "Ep 53: 100%|██████████| 782/782 [00:36<00:00, 21.57batch/s, acc=69.95%, loss=1.03]\n",
            "Ep 54: 100%|██████████| 782/782 [00:36<00:00, 21.65batch/s, acc=70.29%, loss=0.842]\n",
            "Ep 55: 100%|██████████| 782/782 [00:36<00:00, 21.44batch/s, acc=70.37%, loss=0.785]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RnEsKvwU6o2k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
