{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "\n",
        "# ============================================================\n",
        "# PART 1: PHYSICS ENGINE (Shared Atom)\n",
        "# ============================================================\n",
        "class Nucleus(nn.Module):\n",
        "    \"\"\"\n",
        "    [V9.6 Physics] The Grayscale Shape Detector.\n",
        "    Input: 576 Coefficients (24x24x1).\n",
        "    Output: 128 Features.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_coefficients, num_features, num_spline_bins=16, init_mode='random'):\n",
        "        super().__init__()\n",
        "        self.in_dim = num_coefficients\n",
        "        self.out_dim = num_features\n",
        "        self.num_bins = num_spline_bins\n",
        "\n",
        "        # Spectral Permutation (Frequency Analysis)\n",
        "        self.perm_freqs = nn.Parameter(torch.randn(num_features, num_coefficients))\n",
        "        self.perm_phase_shifts = nn.Parameter(torch.rand(num_features, 1))\n",
        "        self.omega_scale = 1.0\n",
        "\n",
        "        # Monotonic Spline (Shape)\n",
        "        self.spline_heights = nn.Parameter(torch.rand(num_features, num_spline_bins))\n",
        "        self.spline_bias = nn.Parameter(torch.zeros(num_features))\n",
        "\n",
        "        # Noise\n",
        "        self.log_sigma = nn.Parameter(torch.ones(num_features) * -5.0)\n",
        "\n",
        "        # Init\n",
        "        with torch.no_grad():\n",
        "            if init_mode == 'identity':\n",
        "                self.perm_freqs.data.uniform_(-0.01, 0.01)\n",
        "                self.spline_heights.data.fill_(1.0 / num_spline_bins)\n",
        "            elif init_mode == 'random':\n",
        "                self.perm_freqs.data.uniform_(-0.5, 0.5)\n",
        "                self.spline_heights.data.uniform_(0.0, 0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, S, 576)\n",
        "        basis_raw = F.linear(x, self.perm_freqs) + self.perm_phase_shifts.T\n",
        "        basis = torch.sin(self.omega_scale * basis_raw)\n",
        "        u = torch.sigmoid(basis)\n",
        "\n",
        "        w = F.softplus(self.spline_heights)\n",
        "        u_expanded = u.unsqueeze(-1)\n",
        "        bin_grid = torch.linspace(0, 1, self.num_bins, device=x.device).view(1, 1, 1, -1)\n",
        "        relu_basis = F.relu(u_expanded - bin_grid)\n",
        "        spline_val = torch.sum(relu_basis * w.view(1, 1, self.out_dim, self.num_bins), dim=-1)\n",
        "        val = spline_val + self.spline_bias.view(1, 1, self.out_dim)\n",
        "\n",
        "        if self.training:\n",
        "            val = val + (torch.randn_like(val) * torch.exp(self.log_sigma).view(1, 1, self.out_dim))\n",
        "        return val\n",
        "\n",
        "class OrbitalShells(nn.Module):\n",
        "    def __init__(self, dim, day_length=64):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.day_length = day_length\n",
        "        # Precompute frequencies for dim/2 pairs\n",
        "        self.register_buffer('inv_freq_h', 1.0 / (10000 ** (torch.arange(0, dim, 2).float() / dim)))\n",
        "        self.register_buffer('inv_freq_d', 1.0 / (100000 ** (torch.arange(0, dim, 2).float() / dim)))\n",
        "\n",
        "    def forward(self, x, start_index=0):\n",
        "        # x: (B, Seq, Dim)\n",
        "        indices = torch.arange(start_index, start_index + x.shape[1], device=x.device).float()\n",
        "        days = indices // self.day_length\n",
        "        hours = indices % self.day_length\n",
        "\n",
        "        # Angles: (Seq, Dim/2)\n",
        "        angles = torch.outer(hours, self.inv_freq_h) + torch.outer(days, self.inv_freq_d)\n",
        "\n",
        "        # Repeat to match full Dim: (Seq, Dim) -> (1, Seq, Dim)\n",
        "        # Pairs: [theta_0, theta_0, theta_1, theta_1...]\n",
        "        theta = torch.repeat_interleave(angles, 2, dim=1).unsqueeze(0)\n",
        "\n",
        "        cos_t = torch.cos(theta)\n",
        "        sin_t = torch.sin(theta)\n",
        "\n",
        "        x_rot = torch.zeros_like(x)\n",
        "\n",
        "        # [FIX] Slice cos_t and sin_t to match x slices (taking even/odd indices)\n",
        "        # Even indices (real part)\n",
        "        x_rot[..., 0::2] = x[..., 0::2] * cos_t[..., 0::2] - x[..., 1::2] * sin_t[..., 0::2]\n",
        "\n",
        "        # Odd indices (imaginary part)\n",
        "        x_rot[..., 1::2] = x[..., 0::2] * sin_t[..., 1::2] + x[..., 1::2] * cos_t[..., 1::2]\n",
        "\n",
        "        return x_rot\n",
        "\n",
        "class Atom(nn.Module):\n",
        "    def __init__(self, dim, patch_dim=None, init_mode='identity'):\n",
        "        super().__init__()\n",
        "        in_dim = patch_dim if patch_dim is not None else dim\n",
        "        self.nucleus = Nucleus(num_coefficients=in_dim, num_features=dim, init_mode=init_mode)\n",
        "        self.shells = OrbitalShells(dim)\n",
        "\n",
        "    def forward(self, x, offset=0):\n",
        "        # x is a stacked sequence of [R, G, B]\n",
        "        # Nucleus processes them all identically (Shared Physics)\n",
        "        identity = self.nucleus(x)\n",
        "        # Shells assign sequential positions 0..47\n",
        "        # R=0..15, G=16..31, B=32..47\n",
        "        situated = self.shells(identity, start_index=offset)\n",
        "        return situated\n",
        "\n",
        "# ============================================================\n",
        "# PART 2: GRAMMAR\n",
        "# ============================================================\n",
        "class MixingNode(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.temperature = nn.Parameter(torch.tensor(1.0))\n",
        "        self.bias = nn.Parameter(torch.zeros(1))\n",
        "        self.layer_norm = nn.LayerNorm(dim)\n",
        "\n",
        "    def forward(self, q, k, v):\n",
        "        affinity = torch.matmul(q, k.transpose(-2, -1))\n",
        "        weights = F.softmax(affinity * self.temperature + self.bias, dim=-1)\n",
        "        out = torch.matmul(weights, v)\n",
        "        return self.layer_norm(out + q)\n",
        "\n",
        "# ============================================================\n",
        "# PART 3: VISION MODULE (Channel Stacked)\n",
        "# ============================================================\n",
        "class DeepCore(nn.Module):\n",
        "    def __init__(self, dim, depth=2):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([])\n",
        "        for _ in range(depth):\n",
        "            self.layers.append(nn.ModuleDict({\n",
        "                'q': Atom(dim, patch_dim=dim, init_mode='identity'),\n",
        "                'k': Atom(dim, patch_dim=dim, init_mode='identity'),\n",
        "                'v': Atom(dim, patch_dim=dim, init_mode='random'),\n",
        "                'mixer': MixingNode(dim)\n",
        "            }))\n",
        "    def forward(self, x):\n",
        "        curr = x\n",
        "        for layer in self.layers:\n",
        "            curr = layer['mixer'](\n",
        "                layer['q'](curr, offset=0),\n",
        "                layer['k'](curr, offset=1),\n",
        "                layer['v'](curr, offset=1)\n",
        "            )\n",
        "        return curr\n",
        "\n",
        "class VisionModule(nn.Module):\n",
        "    def __init__(self, dim=128, patch_size=24, num_classes=10, depth=2):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "        # Interface\n",
        "        self.lens_embed = nn.Linear(4, dim)\n",
        "        self.context_core = nn.Sequential(nn.Linear(dim, dim), nn.Tanh(), nn.Linear(dim, dim))\n",
        "\n",
        "        # RETINA: Input is 576 coeffs (1 channel)\n",
        "        patch_dim_1ch = patch_size * patch_size * 1\n",
        "\n",
        "        # Shared Atoms for R, G, B\n",
        "        self.retina_k = Atom(dim, patch_dim=patch_dim_1ch, init_mode='identity')\n",
        "        self.retina_v = Atom(dim, patch_dim=patch_dim_1ch, init_mode='random')\n",
        "        self.lens_q = Atom(dim, patch_dim=dim, init_mode='identity')\n",
        "\n",
        "        self.input_mixer = MixingNode(dim)\n",
        "        self.deep_core = DeepCore(dim, depth=depth)\n",
        "        self.head = nn.Linear(dim, num_classes)\n",
        "\n",
        "        # Z-Order for 4x4 Grid\n",
        "        self.register_buffer('z_indices', self._precompute_z_order(96, 96, patch_size))\n",
        "\n",
        "    def _precompute_z_order(self, H, W, P):\n",
        "        n_h, n_w = H // P, W // P\n",
        "        coords = sorted([(x, y) for y in range(n_h) for x in range(n_w)],\n",
        "                        key=lambda p: self._morton_code(p[0], p[1]))\n",
        "        return torch.tensor([y * n_w + x for (x, y) in coords], dtype=torch.long)\n",
        "\n",
        "    def _morton_code(self, x, y):\n",
        "        code = 0\n",
        "        for i in range(16): code |= ((x & (1 << i)) << i) | ((y & (1 << i)) << (i + 1))\n",
        "        return code\n",
        "\n",
        "    def forward(self, img):\n",
        "        B, C, H, W = img.shape\n",
        "\n",
        "        # 1. Interface\n",
        "        scale = (H * W) / (96 * 96)\n",
        "        meta = torch.cat([torch.tensor(scale).expand(B, 1).to(img.device),\n",
        "                          img.std(dim=(1,2,3), keepdim=True).squeeze().unsqueeze(1),\n",
        "                          img.mean(dim=(1,2,3), keepdim=True).squeeze().unsqueeze(1),\n",
        "                          torch.ones(B, 1).to(img.device)], dim=1)\n",
        "\n",
        "        # 2. Patchify & Stack\n",
        "        # Unfold gives (B, C*P*P, N_patches)\n",
        "        # We need to process channels independently.\n",
        "        # Reshape to (B, C, P*P, N) -> Transpose to (B, C, N, P*P)\n",
        "        patches_raw = F.unfold(img, kernel_size=self.patch_size, stride=self.patch_size)\n",
        "        patches_reshaped = patches_raw.view(B, C, self.patch_size*self.patch_size, -1)\n",
        "        patches_transposed = patches_reshaped.permute(0, 1, 3, 2) # (B, 3, 16, 576)\n",
        "\n",
        "        # Apply Z-Order per channel\n",
        "        # z_indices handles the N dimension (16)\n",
        "        patches_z = patches_transposed[:, :, self.z_indices, :]\n",
        "\n",
        "        # Stack Channels: (B, 3, 16, 576) -> (B, 48, 576)\n",
        "        # RRR...GGG...BBB...\n",
        "        stream_stacked = patches_z.reshape(B, -1, self.patch_size*self.patch_size)\n",
        "\n",
        "        # 3. Layer 0 (Retina)\n",
        "        lens = self.context_core(self.lens_embed(meta).unsqueeze(1))\n",
        "\n",
        "        # Process the Stacked Stream\n",
        "        # The Atom sees 48 \"Monochrome Texture Patches\"\n",
        "        # RoPE assigns indices 0..47, effectively linearizing C into T\n",
        "        q0 = self.retina_k(stream_stacked, offset=1) + lens\n",
        "        k0 = self.retina_k(stream_stacked, offset=1)\n",
        "        v0 = self.retina_v(stream_stacked, offset=1)\n",
        "\n",
        "        # 4. Deep Core\n",
        "        state = self.input_mixer(q0, k0, v0)\n",
        "        final = self.deep_core(state)\n",
        "\n",
        "        return self.head(final.mean(dim=1))\n",
        "\n",
        "# ============================================================\n",
        "# PART 4: TRAINING (STL-10)\n",
        "# ============================================================\n",
        "def train():\n",
        "    print(\"--- V9.6 Vision System (STL-10 | Channel Stacking | Late Fusion) ---\")\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Device: {device}\")\n",
        "\n",
        "    BATCH_SIZE = 32\n",
        "    EPOCHS = 5\n",
        "    LR = 0.001\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((96, 96)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    print(\"Downloading STL-10...\")\n",
        "    train_set = datasets.STL10(root='./data', split='train', download=True, transform=transform)\n",
        "    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    model = VisionModule(dim=128, patch_size=24, num_classes=10, depth=2).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(EPOCHS):\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for i, (imgs, labels) in enumerate(train_loader):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            if i % 50 == 0:\n",
        "                print(f\"Epoch [{epoch+1}], Step [{i}], Loss: {loss.item():.4f}, Acc: {100.*correct/total:.2f}%\")\n",
        "\n",
        "        print(f\"=== Epoch {epoch+1} Avg Loss: {total_loss/len(train_loader):.4f} ===\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEOYY9OyKrK0",
        "outputId": "a9534547-912e-475b-ea54-6d3fb1f7d1fb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- V9.6 Vision System (STL-10 | Channel Stacking | Late Fusion) ---\n",
            "Device: cpu\n",
            "Downloading STL-10...\n",
            "Epoch [1], Step [0], Loss: 2.4152, Acc: 9.38%\n",
            "Epoch [1], Step [50], Loss: 2.3173, Acc: 9.62%\n",
            "Epoch [1], Step [100], Loss: 2.3374, Acc: 9.68%\n",
            "Epoch [1], Step [150], Loss: 2.3705, Acc: 10.35%\n",
            "=== Epoch 1 Avg Loss: 2.3088 ===\n",
            "Epoch [2], Step [0], Loss: 2.2731, Acc: 12.50%\n",
            "Epoch [2], Step [50], Loss: 2.3030, Acc: 14.71%\n",
            "Epoch [2], Step [100], Loss: 2.2531, Acc: 15.84%\n",
            "Epoch [2], Step [150], Loss: 2.1316, Acc: 17.14%\n",
            "=== Epoch 2 Avg Loss: 2.2269 ===\n",
            "Epoch [3], Step [0], Loss: 2.1895, Acc: 9.38%\n",
            "Epoch [3], Step [50], Loss: 2.0959, Acc: 19.12%\n",
            "Epoch [3], Step [100], Loss: 2.1719, Acc: 19.31%\n",
            "Epoch [3], Step [150], Loss: 2.0306, Acc: 20.94%\n",
            "=== Epoch 3 Avg Loss: 2.1128 ===\n",
            "Epoch [4], Step [0], Loss: 2.0259, Acc: 15.62%\n",
            "Epoch [4], Step [50], Loss: 2.1694, Acc: 25.37%\n",
            "Epoch [4], Step [100], Loss: 2.1228, Acc: 26.02%\n",
            "Epoch [4], Step [150], Loss: 1.9882, Acc: 26.18%\n",
            "=== Epoch 4 Avg Loss: 1.9546 ===\n",
            "Epoch [5], Step [0], Loss: 1.8848, Acc: 21.88%\n",
            "Epoch [5], Step [50], Loss: 2.1125, Acc: 27.63%\n",
            "Epoch [5], Step [100], Loss: 1.7448, Acc: 27.66%\n",
            "Epoch [5], Step [150], Loss: 1.8118, Acc: 27.88%\n",
            "=== Epoch 5 Avg Loss: 1.8948 ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- V9.6 Vision System (STL-10 | Channel Stacking | Late Fusion) ---\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5\n",
        "LR = 0.001\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((96, 96)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "print(\"Downloading STL-10...\")\n",
        "train_set = datasets.STL10(root='./data', split='train', download=True, transform=transform)\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "model = VisionModule(dim=128, patch_size=24, num_classes=10, depth=2).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "GnSs3z_OEBwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a8f00e1-dec2-4e91-9d91-891b3419ce64"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- V9.6 Vision System (STL-10 | Channel Stacking | Late Fusion) ---\n",
            "Device: cpu\n",
            "Downloading STL-10...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.train()\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (imgs, labels) in enumerate(train_loader):\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print(f\"Epoch [{epoch+1}], Step [{i}], Loss: {loss.item():.4f}, Acc: {100.*correct/total:.2f}%\")\n",
        "\n",
        "    print(f\"=== Epoch {epoch+1} Avg Loss: {total_loss/len(train_loader):.4f} ===\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5XIXpIdKVTh",
        "outputId": "d48092f2-c1f5-4888-80ca-f9f3f18e2ac2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1], Step [0], Loss: 2.3484, Acc: 6.25%\n",
            "Epoch [1], Step [50], Loss: 2.2733, Acc: 10.29%\n",
            "Epoch [1], Step [100], Loss: 2.2789, Acc: 10.46%\n",
            "Epoch [1], Step [150], Loss: 2.3342, Acc: 10.99%\n",
            "=== Epoch 1 Avg Loss: 2.3093 ===\n",
            "Epoch [2], Step [0], Loss: 2.2941, Acc: 12.50%\n",
            "Epoch [2], Step [50], Loss: 2.2926, Acc: 11.89%\n",
            "Epoch [2], Step [100], Loss: 2.2240, Acc: 13.34%\n",
            "Epoch [2], Step [150], Loss: 2.1288, Acc: 14.90%\n",
            "=== Epoch 2 Avg Loss: 2.2635 ===\n",
            "Epoch [3], Step [0], Loss: 2.2254, Acc: 9.38%\n",
            "Epoch [3], Step [50], Loss: 2.0098, Acc: 19.30%\n",
            "Epoch [3], Step [100], Loss: 2.1475, Acc: 20.05%\n",
            "Epoch [3], Step [150], Loss: 2.0832, Acc: 20.80%\n",
            "=== Epoch 3 Avg Loss: 2.1000 ===\n",
            "Epoch [4], Step [0], Loss: 1.8989, Acc: 34.38%\n",
            "Epoch [4], Step [50], Loss: 1.7918, Acc: 27.02%\n",
            "Epoch [4], Step [100], Loss: 2.1128, Acc: 25.74%\n",
            "Epoch [4], Step [150], Loss: 1.9111, Acc: 26.18%\n",
            "=== Epoch 4 Avg Loss: 1.9354 ===\n",
            "Epoch [5], Step [0], Loss: 1.8339, Acc: 25.00%\n",
            "Epoch [5], Step [50], Loss: 1.9965, Acc: 26.90%\n",
            "Epoch [5], Step [100], Loss: 1.8780, Acc: 28.03%\n",
            "Epoch [5], Step [150], Loss: 1.8290, Acc: 27.19%\n",
            "=== Epoch 5 Avg Loss: 1.8915 ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.train()\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (imgs, labels) in enumerate(train_loader):\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print(f\"Epoch [{epoch+1}], Step [{i}], Loss: {loss.item():.4f}, Acc: {100.*correct/total:.2f}%\")\n",
        "\n",
        "    print(f\"=== Epoch {epoch+1} Avg Loss: {total_loss/len(train_loader):.4f} ===\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmZQh6KcKZ0V",
        "outputId": "c87b1191-77df-4651-f53d-2e5f40ea6caa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1], Step [0], Loss: 1.9506, Acc: 18.75%\n",
            "Epoch [1], Step [50], Loss: 1.8081, Acc: 30.02%\n",
            "Epoch [1], Step [100], Loss: 1.7015, Acc: 30.01%\n",
            "Epoch [1], Step [150], Loss: 1.8772, Acc: 30.03%\n",
            "=== Epoch 1 Avg Loss: 1.8513 ===\n",
            "Epoch [2], Step [0], Loss: 1.9908, Acc: 18.75%\n",
            "Epoch [2], Step [50], Loss: 1.9483, Acc: 28.43%\n",
            "Epoch [2], Step [100], Loss: 1.9730, Acc: 29.02%\n",
            "Epoch [2], Step [150], Loss: 1.6854, Acc: 29.12%\n",
            "=== Epoch 2 Avg Loss: 1.8421 ===\n",
            "Epoch [3], Step [0], Loss: 1.7571, Acc: 25.00%\n",
            "Epoch [3], Step [50], Loss: 2.0518, Acc: 31.92%\n",
            "Epoch [3], Step [100], Loss: 1.8594, Acc: 30.88%\n",
            "Epoch [3], Step [150], Loss: 1.4683, Acc: 31.02%\n",
            "=== Epoch 3 Avg Loss: 1.7935 ===\n",
            "Epoch [4], Step [0], Loss: 2.0556, Acc: 34.38%\n",
            "Epoch [4], Step [50], Loss: 1.8121, Acc: 32.17%\n",
            "Epoch [4], Step [100], Loss: 1.6895, Acc: 32.18%\n",
            "Epoch [4], Step [150], Loss: 1.8267, Acc: 31.79%\n",
            "=== Epoch 4 Avg Loss: 1.7595 ===\n",
            "Epoch [5], Step [0], Loss: 2.1563, Acc: 12.50%\n",
            "Epoch [5], Step [50], Loss: 1.8843, Acc: 35.66%\n",
            "Epoch [5], Step [100], Loss: 1.8302, Acc: 34.81%\n",
            "Epoch [5], Step [150], Loss: 1.6566, Acc: 34.02%\n",
            "=== Epoch 5 Avg Loss: 1.7282 ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.train()\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (imgs, labels) in enumerate(train_loader):\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print(f\"Epoch [{epoch+1}], Step [{i}], Loss: {loss.item():.4f}, Acc: {100.*correct/total:.2f}%\")\n",
        "\n",
        "    print(f\"=== Epoch {epoch+1} Avg Loss: {total_loss/len(train_loader):.4f} ===\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzwuDxhYLKYN",
        "outputId": "9eb3e22f-a549-449f-e408-85fa0a901711"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1], Step [0], Loss: 1.6886, Acc: 40.62%\n",
            "Epoch [1], Step [50], Loss: 1.4757, Acc: 35.91%\n",
            "Epoch [1], Step [100], Loss: 1.8904, Acc: 33.35%\n",
            "Epoch [1], Step [150], Loss: 1.6880, Acc: 33.88%\n",
            "=== Epoch 1 Avg Loss: 1.6947 ===\n",
            "Epoch [2], Step [0], Loss: 1.5929, Acc: 31.25%\n",
            "Epoch [2], Step [50], Loss: 1.7762, Acc: 36.52%\n",
            "Epoch [2], Step [100], Loss: 1.6511, Acc: 35.89%\n",
            "Epoch [2], Step [150], Loss: 1.5621, Acc: 35.97%\n",
            "=== Epoch 2 Avg Loss: 1.6627 ===\n",
            "Epoch [3], Step [0], Loss: 1.7669, Acc: 34.38%\n",
            "Epoch [3], Step [50], Loss: 1.7638, Acc: 38.79%\n",
            "Epoch [3], Step [100], Loss: 1.7682, Acc: 38.00%\n",
            "Epoch [3], Step [150], Loss: 1.7388, Acc: 37.19%\n",
            "=== Epoch 3 Avg Loss: 1.6404 ===\n",
            "Epoch [4], Step [0], Loss: 1.3900, Acc: 43.75%\n",
            "Epoch [4], Step [50], Loss: 1.6163, Acc: 37.93%\n",
            "Epoch [4], Step [100], Loss: 1.5590, Acc: 37.96%\n",
            "Epoch [4], Step [150], Loss: 1.2372, Acc: 38.06%\n",
            "=== Epoch 4 Avg Loss: 1.6132 ===\n",
            "Epoch [5], Step [0], Loss: 1.4749, Acc: 59.38%\n",
            "Epoch [5], Step [50], Loss: 1.4335, Acc: 42.71%\n",
            "Epoch [5], Step [100], Loss: 1.5825, Acc: 40.56%\n",
            "Epoch [5], Step [150], Loss: 1.8966, Acc: 39.69%\n",
            "=== Epoch 5 Avg Loss: 1.5825 ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.train()\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (imgs, labels) in enumerate(train_loader):\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        if i % 50 == 0:\n",
        "            print(f\"Epoch [{epoch+1}], Step [{i}], Loss: {loss.item():.4f}, Acc: {100.*correct/total:.2f}%\")\n",
        "\n",
        "    print(f\"=== Epoch {epoch+1} Avg Loss: {total_loss/len(train_loader):.4f} ===\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHInbtSWL4_F",
        "outputId": "18d4d380-e591-47ae-a5c0-1b4d3b18ca68"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1], Step [0], Loss: 1.4944, Acc: 43.75%\n",
            "Epoch [1], Step [50], Loss: 1.3289, Acc: 43.50%\n",
            "Epoch [1], Step [100], Loss: 1.3987, Acc: 42.17%\n",
            "Epoch [1], Step [150], Loss: 1.4780, Acc: 41.25%\n",
            "=== Epoch 1 Avg Loss: 1.5395 ===\n",
            "Epoch [2], Step [0], Loss: 1.3046, Acc: 43.75%\n",
            "Epoch [2], Step [50], Loss: 1.3881, Acc: 44.42%\n",
            "Epoch [2], Step [100], Loss: 1.5920, Acc: 44.86%\n",
            "Epoch [2], Step [150], Loss: 1.2887, Acc: 44.14%\n",
            "=== Epoch 2 Avg Loss: 1.4858 ===\n",
            "Epoch [3], Step [0], Loss: 1.6957, Acc: 40.62%\n",
            "Epoch [3], Step [50], Loss: 1.1756, Acc: 47.37%\n",
            "Epoch [3], Step [100], Loss: 1.5331, Acc: 46.44%\n",
            "Epoch [3], Step [150], Loss: 1.5685, Acc: 45.80%\n",
            "=== Epoch 3 Avg Loss: 1.4390 ===\n",
            "Epoch [4], Step [0], Loss: 1.0830, Acc: 71.88%\n",
            "Epoch [4], Step [50], Loss: 1.3766, Acc: 49.94%\n",
            "Epoch [4], Step [100], Loss: 1.5160, Acc: 48.24%\n",
            "Epoch [4], Step [150], Loss: 1.2676, Acc: 47.83%\n",
            "=== Epoch 4 Avg Loss: 1.3840 ===\n",
            "Epoch [5], Step [0], Loss: 1.3026, Acc: 50.00%\n",
            "Epoch [5], Step [50], Loss: 1.1956, Acc: 50.67%\n",
            "Epoch [5], Step [100], Loss: 1.1728, Acc: 50.37%\n",
            "Epoch [5], Step [150], Loss: 1.3803, Acc: 49.23%\n",
            "=== Epoch 5 Avg Loss: 1.3583 ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "78YfiuSVM2Xd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
