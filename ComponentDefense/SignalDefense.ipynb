{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Graph Model Implementation Notes\n",
        "    Version 9.2 introduces the **Recursive Expression Engine**\n",
        "    (a learnable grammatical compute model)\n",
        "    and **Cylindrical Time** (hierarchical rotary embeddings),\n",
        "    integrating them with the **Fractal Topology**\n",
        "    and **Relativistic Economics** of Versions 6–9.\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "from typing import List, Dict, Optional, Any, Union, Tuple, Deque\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "\n",
        "# ============================================================\n",
        "# SECTION 1 — The Physics Layer (Universal Representations)\n",
        "# ============================================================\n",
        "\n",
        "class LossComplexity:\n",
        "    \"\"\"\n",
        "    [Restored from V6/User Request]\n",
        "    The Relativistic Barrier.\n",
        "    Manages the 'Architectural Energy' of a module.\n",
        "    \"\"\"\n",
        "    def __init__(self, limit_space: float = 1e6, limit_time: float = 100.0):\n",
        "        self.limit_space = limit_space\n",
        "        self.limit_time = limit_time\n",
        "\n",
        "        # Curvature Gamma (Learnable by MindsEye)\n",
        "        # Higher Gamma = Harder Wall. Lower Gamma = Softer Wall.\n",
        "        self.gamma = 1.0\n",
        "\n",
        "        self.current_space = 0.0\n",
        "        self.current_time = 0.0\n",
        "\n",
        "    def get_barrier_penalty(self) -> float:\n",
        "        \"\"\"\n",
        "        Calculates the relativistic cost as complexity approaches the limit.\n",
        "        Cost -> Infinity as Current -> Limit.\n",
        "        Formula: 1 / sqrt(1 - (C/Limit)^2)\n",
        "        \"\"\"\n",
        "        # Clip to 0.99 to prevent divide-by-zero\n",
        "        ratio_s = min(self.current_space / self.limit_space, 0.99)\n",
        "        ratio_t = min(self.current_time / self.limit_time, 0.99)\n",
        "\n",
        "        penalty_s = 1.0 / np.sqrt(1.0 - ratio_s**2)\n",
        "        penalty_t = 1.0 / np.sqrt(1.0 - ratio_t**2)\n",
        "\n",
        "        return (penalty_s + penalty_t) * self.gamma\n",
        "\n",
        "    def distribute_tokens(self, amount_space: float, amount_time: float) -> bool:\n",
        "        \"\"\"\n",
        "        Attempts to allocate complexity tokens for child processes/atoms.\n",
        "        Returns False if barrier makes cost prohibitive (Hard Stop).\n",
        "        In a differentiable setting, this would return a high gradient cost.\n",
        "        \"\"\"\n",
        "        new_s = self.current_space + amount_space\n",
        "        new_t = self.current_time + amount_time\n",
        "\n",
        "        if new_s >= self.limit_space or new_t >= self.limit_time:\n",
        "            return False\n",
        "\n",
        "        self.current_space = new_s\n",
        "        self.current_time = new_t\n",
        "        return True\n",
        "\n",
        "\n",
        "class UniversalWorm:\n",
        "    \"\"\"[Restored from V8] Helper for Z-Order Linearization.\"\"\"\n",
        "    def z_order_argsort(self, coords: np.ndarray) -> np.ndarray:\n",
        "        # Placeholder for Morton Code calculation\n",
        "        # Ensures N-dim grid -> 1D stream locality preservation\n",
        "        return np.arange(len(coords))\n",
        "\n",
        "class CylindricalRoPE:\n",
        "    \"\"\"\n",
        "    [V9.2 New Logic]\n",
        "    Hierarchical Rotary Positional Embeddings.\n",
        "    Maps linear sequence time to Cylindrical Coordinates (Day, Hour).\n",
        "\n",
        "    - Axis 1 (Hour): High-frequency local rotation (Standard RoPE).\n",
        "    - Axis 2 (Day): Low-frequency global rotation (Spiral).\n",
        "\n",
        "    This composition allows for infinite sequence length (Day count) while\n",
        "    preserving high-precision relative distances within the local context (Hour).\n",
        "    \"\"\"\n",
        "    def __init__(self, dim: int, day_length: int = 1024):\n",
        "        self.dim = dim\n",
        "        self.day_length = day_length\n",
        "\n",
        "        # Standard frequencies for the 'Hour' (Local/Ring)\n",
        "        # Base 10000 is standard for capturing local syntax\n",
        "        inv_freq_h = 1.0 / (10000 ** (np.arange(0, dim, 2) / dim))\n",
        "        self.freqs_hour = inv_freq_h\n",
        "\n",
        "        # Slower frequencies for the 'Day' (Global/Spiral)\n",
        "        # Base 100000 ensures the spiral evolves slowly compared to the ring\n",
        "        inv_freq_d = 1.0 / (100000 ** (np.arange(0, dim, 2) / dim))\n",
        "        self.freqs_day = inv_freq_d\n",
        "\n",
        "    def apply(self, x: np.ndarray, start_index: int = 0) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Applies cylindrical rotation to input batch x.\n",
        "        x shape: (seq_len, dim)\n",
        "        \"\"\"\n",
        "        seq_len, dim = x.shape\n",
        "        indices = np.arange(start_index, start_index + seq_len)\n",
        "\n",
        "        # 1. Decompose Linear Index into Cylindrical (Day, Hour)\n",
        "        days = indices // self.day_length\n",
        "        hours = indices % self.day_length\n",
        "\n",
        "        # 2. Compute Angles (Broadcasting)\n",
        "        # Outer product to get angles for every feature pair\n",
        "        angles_h = np.outer(hours, self.freqs_hour) # (seq, dim/2)\n",
        "        angles_d = np.outer(days, self.freqs_day)   # (seq, dim/2)\n",
        "\n",
        "        # 3. Composite Rotation (The Spiral)\n",
        "        # Summing angles is mathematically equivalent to rotating by Hour then by Day\n",
        "        total_angle = angles_h + angles_d\n",
        "\n",
        "        # 4. Apply Rotation to pairs [x0, x1]\n",
        "        # Repeat angles for both parts of the pair\n",
        "        theta = np.repeat(total_angle, 2, axis=1)\n",
        "\n",
        "        # Prepare cos/sin\n",
        "        cos_t = np.cos(theta)\n",
        "        sin_t = np.sin(theta)\n",
        "\n",
        "        # Apply standard rotary formula\n",
        "        # [-x1, x0] * sin + [x0, x1] * cos\n",
        "        x_rotated = np.empty_like(x)\n",
        "        x_rotated[:, 0::2] = x[:, 0::2] * cos_t[:, 0::2] - x[:, 1::2] * sin_t[:, 0::2]\n",
        "        x_rotated[:, 1::2] = x[:, 0::2] * sin_t[:, 0::2] + x[:, 1::2] * cos_t[:, 0::2]\n",
        "\n",
        "        return x_rotated\n",
        "\n",
        "class Feature:\n",
        "    \"\"\"\n",
        "    [V9 Factorization]\n",
        "    Composite Object: Spline (Physics) + Permutation (Geometry) + Noise (Entropy).\n",
        "    \"\"\"\n",
        "    def __init__(self, embedding_dim: int):\n",
        "        self.spline_knots = np.zeros(embedding_dim)\n",
        "        # [Restored V7] Dual-Axis: Row (Topology) & Column (Semantic)\n",
        "        self.perm_row_coeffs = np.zeros(embedding_dim)\n",
        "        self.perm_col_coeffs = np.zeros(embedding_dim)\n",
        "        # [Restored V8] Renormalization Entropy\n",
        "        self.noise_variance = np.ones(embedding_dim) * 1e-5\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SECTION 2 — The Atom Layer (Generalized Primitive)\n",
        "# ============================================================\n",
        "\n",
        "class Aperture:\n",
        "    \"\"\"[Restored V7/V9] Differentiable Window (Global -> Local).\"\"\"\n",
        "    def __init__(self):\n",
        "        self.sigma = 1e6\n",
        "\n",
        "class Atom:\n",
        "    \"\"\"[V9] The Computational Leaf.\"\"\"\n",
        "    def __init__(self, embedding_dim: int, is_virtual: bool = True, init_mode: str = \"identity\"):\n",
        "        self.is_virtual = is_virtual\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        # [V9.2 FIX] Restore the learnable weights directly in Atom\n",
        "        if init_mode == \"identity\":\n",
        "            # Start as Identity (Pass-through)\n",
        "            self.weights = np.eye(embedding_dim)\n",
        "        else:\n",
        "            # Start as Random (Active Projection for Q)\n",
        "            self.weights = np.random.randn(embedding_dim, embedding_dim) * 0.02\n",
        "\n",
        "        self.aperture = Aperture()\n",
        "        self.feature = Feature(embedding_dim)\n",
        "\n",
        "        # [V9.2 Update] Hierarchical Position\n",
        "        self.rope = CylindricalRoPE(embedding_dim, day_length=1024)\n",
        "\n",
        "        self.latency_cost = 0.1 if is_virtual else 1.0\n",
        "\n",
        "    def realize(self):\n",
        "        \"\"\"Transition from Virtual to Real.\"\"\"\n",
        "        self.is_virtual = False\n",
        "        self.latency_cost = 1.0\n",
        "\n",
        "    def process(self, input_stream: np.ndarray, stream_offset: int = 0) -> np.ndarray:\n",
        "        if self.is_virtual: return input_stream\n",
        "\n",
        "        # 1. Apply Cylindrical Rotary Embedding\n",
        "        x = self.rope.apply(input_stream, start_index=stream_offset)\n",
        "\n",
        "        # 2. Apply Projection (The \"Channel Mixing\" logic, now native to Atom)\n",
        "        # This allows Q to be different from K/V\n",
        "        x = np.dot(x, self.weights)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SECTION 3 — The Core Layer (Recursive Expression Tree)\n",
        "# ============================================================\n",
        "\n",
        "class LearnablePhi:\n",
        "    \"\"\"\n",
        "    [V9.2 New Logic] Continuous Normalization Function.\n",
        "    Learns to be Identity, Softmax, or Tanh.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.scale = 1.0\n",
        "        self.shift = 0.0\n",
        "        self.temperature = 1.0\n",
        "\n",
        "    def apply(self, x: np.ndarray) -> np.ndarray:\n",
        "        x_affine = (x * self.scale) + self.shift\n",
        "        exp_x = np.exp(x_affine * self.temperature)\n",
        "        return exp_x / (np.sum(exp_x, axis=-1, keepdims=True) + 1e-6)\n",
        "\n",
        "class MixingNode:\n",
        "    \"\"\"\n",
        "    [V9.2 New Logic] The Recursive N-ary Operator.\n",
        "    Executes children then performs sequential reduction.\n",
        "    \"\"\"\n",
        "    def __init__(self, children: List[Union['MixingNode', Atom]]):\n",
        "        self.children = children\n",
        "        # One Phi for each mixing step in the pipe\n",
        "        self.phis = [LearnablePhi() for _ in range(len(children) - 1)]\n",
        "\n",
        "    def execute(self, x: np.ndarray) -> np.ndarray:\n",
        "        # 1. Resolve Children (Recursion)\n",
        "        resolved_vectors = [\n",
        "            c.process(x) if isinstance(c, Atom) else c.execute(x)\n",
        "            for c in self.children\n",
        "        ]\n",
        "\n",
        "        # 2. Sequential Reduction (Left-Associative Pipe)\n",
        "        v_acc = resolved_vectors[0]\n",
        "\n",
        "        for i, v_next in enumerate(resolved_vectors[1:]):\n",
        "            phi = self.phis[i]\n",
        "\n",
        "            # Generalized Interaction (Dot Product)\n",
        "            if v_acc.ndim == 2 and v_next.ndim == 2:\n",
        "                if v_acc.shape == v_next.shape:\n",
        "                    # (N, D) @ (N, D).T -> (N, N) [Affinity Map]\n",
        "                    v_mix = np.dot(v_acc, v_next.T)\n",
        "                elif v_acc.shape[0] == v_acc.shape[1]:\n",
        "                    # (N, N) @ (N, D) -> (N, D) [Apply Map]\n",
        "                    v_mix = np.dot(v_acc, v_next)\n",
        "                else:\n",
        "                    v_mix = v_acc * v_next\n",
        "            else:\n",
        "                v_mix = v_acc * v_next\n",
        "\n",
        "            v_acc = phi.apply(v_mix)\n",
        "\n",
        "        return v_acc\n",
        "\n",
        "class Core:\n",
        "    \"\"\"\n",
        "    [V9.2 Updated Logic]\n",
        "    Constructs the recursive Mixing Tree.\n",
        "    \"\"\"\n",
        "    def __init__(self, embedding_dim: int, topology_def: List = None):\n",
        "        self.embedding_dim = embedding_dim\n",
        "\n",
        "        if topology_def is None:\n",
        "            # Default Initialization: [[Q, K], V]\n",
        "            # Q: Active (Random Init)\n",
        "            # K, V: Passive (Identity Init)\n",
        "\n",
        "            q_atom = Atom(embedding_dim, init_mode=\"random\")\n",
        "            k_atom = Atom(embedding_dim, init_mode=\"identity\")\n",
        "            v_atom = Atom(embedding_dim, init_mode=\"identity\")\n",
        "\n",
        "            # Step 1: The Attention Map Node [Q, K]\n",
        "            # Result is (N, N) affinity matrix\n",
        "            attn_node = MixingNode([q_atom, k_atom])\n",
        "\n",
        "            # Step 2: The Application Node [AttnMap, V]\n",
        "            # Result is (N, D) output\n",
        "            self.root = MixingNode([attn_node, v_atom])\n",
        "        else:\n",
        "            # TODO: Parser for arbitrary lists\n",
        "            self.root = None\n",
        "\n",
        "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
        "        return self.root.execute(x)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SECTION 4 — Logistics & Economy (Restored)\n",
        "# ============================================================\n",
        "\n",
        "class ImpedanceCurve:\n",
        "    \"\"\"\n",
        "    [Restored from V7]\n",
        "    Defines connection cost based on Tree Distance.\n",
        "    Regulates graph topology to prevent 'Small World' collapse.\n",
        "    \"\"\"\n",
        "    def __init__(self, max_distance: int = 33):\n",
        "        self.curve_knots = np.linspace(0, 10, 8) # Monotone Spline\n",
        "\n",
        "    def get_cost(self, sender_node: Module, receiver_node: Module) -> float:\n",
        "        # [V9.1 Logic] Calculate Tree Distance in the Fractal Hierarchy\n",
        "        # dist = tree_distance(sender_node, receiver_node)\n",
        "        # Placeholder distance:\n",
        "        dist = abs(sender_node.level - receiver_node.level)\n",
        "\n",
        "        # Cost increases with distance (Impedance)\n",
        "        return float(dist ** 2) * 0.1\n",
        "\n",
        "class Logistics:\n",
        "    \"\"\"\n",
        "    [Restored from V7/V9]\n",
        "    Manages the Economy: Sender-Pays-Time / Receiver-Pays-Space.\n",
        "    Manages Rhythm: Internal Clock & ETA.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.clock = 0\n",
        "        self.message_queue = deque()\n",
        "        self.temporal_error_history = [] # For Rhythm gradients\n",
        "\n",
        "    def tick(self):\n",
        "        self.clock += 1\n",
        "\n",
        "    def calculate_eta(self, path_latency: float) -> int:\n",
        "        return self.clock + int(np.ceil(path_latency))\n",
        "\n",
        "    def register_arrival(self, predicted_eta: int):\n",
        "        \"\"\"[V6 Rhythm Logic] Calculate temporal error for gradient.\"\"\"\n",
        "        actual_arrival = self.clock\n",
        "        # Penalize Late Arrival (Inefficiency) AND Early Arrival (Rhythm Break)\n",
        "        error = (actual_arrival - predicted_eta) ** 2\n",
        "        self.temporal_error_history.append(error)\n",
        "\n",
        "class Connector:\n",
        "    \"\"\"\n",
        "    [Restored V7] Receiver-Centric Input Port.\n",
        "    \"\"\"\n",
        "    def __init__(self, embedding_dim: int):\n",
        "        self.buffer = deque(maxlen=16)\n",
        "        self.alignment_mode = \"DualAxisSpectral\" # [Restored V7]\n",
        "        self.impedance_cost = 0.0\n",
        "\n",
        "# ============================================================\n",
        "# SECTION 5 — The Module Layer (Recursive Agent)\n",
        "# ============================================================\n",
        "\n",
        "class Trinity:\n",
        "    \"\"\"[V7/V8/V9] Context -> State -> Service.\"\"\"\n",
        "    def __init__(self, embedding_dim: int):\n",
        "        self.context = Core(embedding_dim)\n",
        "        self.state = Core(embedding_dim)\n",
        "        self.service = Core(embedding_dim)\n",
        "\n",
        "    def cycle(self, x: np.ndarray) -> np.ndarray:\n",
        "        c = self.context.forward(x)\n",
        "        s = self.state.forward(c)\n",
        "        return self.service.forward(s)\n",
        "\n",
        "class Module:\n",
        "    \"\"\"\n",
        "    [V9 Integrated]\n",
        "    Recursive Container. Manages internal sparsity via sub_modules.\n",
        "    Enforces LossComplexity (Relativistic Barrier).\n",
        "    \"\"\"\n",
        "    def __init__(self, module_id: str, level: int, embedding_dim: int = 256):\n",
        "        self.id = module_id\n",
        "        self.level = level\n",
        "        self.is_virtual = True\n",
        "\n",
        "        # [V9] Internal Sparsity (Strictly Private)\n",
        "        # Recursive definition: A Module contains Modules.\n",
        "        self.sub_modules: List[Module] = []\n",
        "\n",
        "        # [V9] Local Compute\n",
        "        self.trinity = Trinity(embedding_dim)\n",
        "\n",
        "        # [V6/V9] Relativistic Budget Holder\n",
        "        # Aggregates complexity of Self + Realized Children\n",
        "        self.complexity = LossComplexity()\n",
        "\n",
        "        # [V7] External Connectivity\n",
        "        self.connectors: Dict[str, Connector] = {}\n",
        "\n",
        "    def ensure_connector(self, sender: Module, impedance_curve: ImpedanceCurve):\n",
        "        \"\"\"\n",
        "        Establishes connection governed by Impedance Cost (Space Tokens).\n",
        "        \"\"\"\n",
        "        if sender.id not in self.connectors:\n",
        "            cost = impedance_curve.get_cost(sender, self)\n",
        "            # Check if we can afford the Space Cost (Relativistic Barrier)\n",
        "            if self.complexity.distribute_tokens(amount_space=cost, amount_time=0):\n",
        "                self.connectors[sender.id] = Connector(256)\n",
        "                self.connectors[sender.id].impedance_cost = cost\n",
        "\n",
        "    def process(self, signal: Any) -> Any:\n",
        "        \"\"\"\n",
        "        Recursive Execution Flow.\n",
        "        \"\"\"\n",
        "        if self.is_virtual:\n",
        "            return signal # Zero cost, identity pass-through\n",
        "\n",
        "        # 1. Distribute Complexity to Sub-Modules (Internal Sparsity)\n",
        "        # If a sub-module is realized, it consumes part of THIS module's budget.\n",
        "        if self.sub_modules:\n",
        "            for sub in self.sub_modules:\n",
        "                # Sub-modules communicate only with Parent, not outside.\n",
        "                signal = sub.process(signal)\n",
        "\n",
        "        # 2. Local Cycle\n",
        "        output = self.trinity.cycle(signal)\n",
        "\n",
        "        # 3. Update Time Complexity (Sender-Pays-Time)\n",
        "        self.complexity.current_time += 1.0\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# SECTION 6 — The Mind Layer (Bicameral & Meta-Context)\n",
        "# ============================================================\n",
        "\n",
        "class Interface:\n",
        "    \"\"\"[V8] Universal Linearization Gateway.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.worm = UniversalWorm()\n",
        "\n",
        "    def linearize(self, data: Any, mode: str = \"metric\") -> Dict:\n",
        "        # [Restored V8] Z-Order or Spectral Linearization\n",
        "        return {\"stream\": data, \"topology_token\": None}\n",
        "\n",
        "class Mind:\n",
        "    \"\"\"Base Hemisphere.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.modules: List[Module] = []\n",
        "        self.logistics = Logistics()\n",
        "        self.impedance = ImpedanceCurve()\n",
        "        self.interface = Interface()\n",
        "\n",
        "        # [Restored V6] Meta-Context Learning Regimes\n",
        "        # MindsEye switches these based on global stability.\n",
        "        self.learning_regime = {\n",
        "            \"batch_size\": 32,\n",
        "            \"learning_rate\": 1e-3,\n",
        "            \"strategy\": \"online\" # or \"batch\", \"structural\"\n",
        "        }\n",
        "\n",
        "class Reflective(Mind):\n",
        "    \"\"\"Hemisphere B: Write-Access, Evolution.\"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.minds_eye = Module(\"minds_eye\", level=33)\n",
        "        # [Restored V6/V9] Version Control for Backtracking\n",
        "        self.checkpoints = {}\n",
        "\n",
        "class GraphModel:\n",
        "    \"\"\"The Integrated God Class.\"\"\"\n",
        "    def __init__(self):\n",
        "        self.active_mind = Mind() # Active (Read-Only)\n",
        "        self.reflective_mind = Reflective() # Reflective (Write-Access)\n",
        "\n",
        "    def forward(self, x: Any):\n",
        "        # 1. Linearize Input\n",
        "        packet = self.active_mind.interface.linearize(x)\n",
        "\n",
        "        # 2. Propagate\n",
        "        # Real logic would traverse the active_mind.modules graph\n",
        "        pass\n"
      ],
      "metadata": {
        "id": "N7eHC8Wa6pnD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from typing import Dict, Any, Tuple\n",
        "# Import the V9.2 Core components\n",
        "# from implementation_version_9_2 import Module, Trinity, Core, Atom, UniversalWorm\n",
        "\n",
        "# ============================================================\n",
        "# Vision Extension (V9.2)\n",
        "# ============================================================\n",
        "\n",
        "class VisionInterface:\n",
        "    \"\"\"\n",
        "    [V9.2 Vision Component]\n",
        "    Translates 2D Images into Universal 1D Streams + Metadata.\n",
        "    \"\"\"\n",
        "    def __init__(self, patch_size: int = 4):\n",
        "        self.patch_size = patch_size\n",
        "        self.worm = UniversalWorm()\n",
        "\n",
        "    def process(self, image: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Input: Image (H, W, C)\n",
        "        Output: (Metadata_Vector, Z_Ordered_Stream)\n",
        "        \"\"\"\n",
        "        H, W, C = image.shape\n",
        "\n",
        "        # 1. Extract Metadata (The \"Context\" Signal)\n",
        "        # Statistics that define the 'Scale' and 'Texture' profile globally\n",
        "        mean_lum = np.mean(image)\n",
        "        std_lum = np.std(image) # Entropy proxy\n",
        "        scale_factor = (H * W) / (256 * 256) # Relative to a 'standard' size\n",
        "\n",
        "        # Metadata: [Scale, Entropy, Mean, 1.0 (Bias)]\n",
        "        metadata = np.array([[scale_factor, std_lum, mean_lum, 1.0]])\n",
        "\n",
        "        # 2. Patchify & Linearize (The \"State\" Signal)\n",
        "        # Simple grid breakdown\n",
        "        n_h = H // self.patch_size\n",
        "        n_w = W // self.patch_size\n",
        "        patches = image.reshape(n_h, self.patch_size, n_w, self.patch_size, C)\n",
        "        patches = patches.transpose(0, 2, 1, 3, 4).reshape(-1, self.patch_size*self.patch_size*C)\n",
        "\n",
        "        # 3. Z-Order Sort (Preserve 2D Locality in 1D)\n",
        "        # Create grid coordinates (y, x) for every patch\n",
        "        y_coords = np.repeat(np.arange(n_h), n_w)\n",
        "        x_coords = np.tile(np.arange(n_w), n_h)\n",
        "        coords = np.stack([y_coords, x_coords], axis=1)\n",
        "\n",
        "        # The Worm calculates the fractal path index for each coordinate\n",
        "        sort_indices = self.worm.z_order_argsort(coords)\n",
        "\n",
        "        # Reorder the linear stream to follow the curve\n",
        "        ordered_stream = patches[sort_indices]\n",
        "\n",
        "        return metadata, ordered_stream\n",
        "\n",
        "class VisionTrinity(Trinity):\n",
        "    \"\"\"\n",
        "    [V9.2 Vision Logic]\n",
        "    Overloads the standard cycle to split Metadata (Lens) and Stream (Pixel).\n",
        "    \"\"\"\n",
        "    def cycle(self, inputs: Tuple[np.ndarray, np.ndarray]) -> np.ndarray:\n",
        "        metadata, pixel_stream = inputs\n",
        "\n",
        "        # 1. Context Core: Set the \"Lens\"\n",
        "        # Input: Simple Global Stats (Scale, Entropy)\n",
        "        # Output: A \"Lens Vector\" that encodes HOW to look at the image\n",
        "        # e.g., \"Ignore high-freq noise\" or \"Focus on edges\"\n",
        "        lens_vector = self.context.forward(metadata)\n",
        "\n",
        "        # 2. State Core: Look at Pixels through the Lens\n",
        "        # We prepend the Lens Vector to the stream.\n",
        "        # The Recursive Engine will mix [Lens, Patch1, Patch2...]\n",
        "        # The Lens Vector acts as the 'Query' or 'Instruction' for the stream.\n",
        "        combined_stream = np.concatenate([lens_vector, pixel_stream], axis=0)\n",
        "\n",
        "        state_representation = self.state.forward(combined_stream)\n",
        "\n",
        "        # 3. Service Core: Classification / Action\n",
        "        # Takes the final state (which is now the image digested by the lens)\n",
        "        return self.service.forward(state_representation)\n",
        "\n",
        "class VisionModule(Module):\n",
        "    \"\"\"\n",
        "    [V9.2 Concrete Implementation]\n",
        "    A Module specialized for 2D visual classification using Scale Equivariance.\n",
        "    \"\"\"\n",
        "    def __init__(self, module_id: str, embedding_dim: int = 64, patch_size: int = 4):\n",
        "        super().__init__(module_id, level=1, embedding_dim=embedding_dim)\n",
        "\n",
        "        # Swap the generic Trinity for our Vision-specific one\n",
        "        self.trinity = VisionTrinity(embedding_dim)\n",
        "        self.interface = VisionInterface(patch_size)\n",
        "\n",
        "        # Initialize Cores with specific roles\n",
        "        # Context: Needs to be simple (Metadata processing)\n",
        "        self.trinity.context = Core(embedding_dim) # Default flat topology is fine\n",
        "\n",
        "        # State: Needs deep mixing (The \"Eye\")\n",
        "        # We could initialize a deeper topology here if we wanted\n",
        "        self.trinity.state = Core(embedding_dim)\n",
        "\n",
        "    def process_image(self, image: np.ndarray) -> Any:\n",
        "        # 1. Linearize via Interface (Z-Order + Metadata extraction)\n",
        "        metadata, stream = self.interface.process(image)\n",
        "\n",
        "        # 2. Project inputs to Embedding Dimension (Simple Linear adapter)\n",
        "        # (In a real Torch model, this would be a learned Linear layer)\n",
        "        # Mocking projection for numpy demo:\n",
        "        meta_proj = np.tile(metadata, (1, self.trinity.context.embedding_dim // 4))\n",
        "        stream_proj = np.pad(stream, ((0,0), (0, max(0, self.trinity.state.embedding_dim - stream.shape[1]))))\n",
        "\n",
        "        # 3. Execute the Cycle\n",
        "        # Context (Lens) -> State (Eye) -> Service (Label)\n",
        "        result = self.trinity.cycle((meta_proj, stream_proj))\n",
        "\n",
        "        return result\n",
        "\n",
        "# ============================================================\n",
        "# Unit Test / Verification\n",
        "# ============================================================\n",
        "if __name__ == \"__main__\":\n",
        "    # 1. Create the Module\n",
        "    vision_mod = VisionModule(\"visual_cortex_v1\", embedding_dim=128)\n",
        "\n",
        "    # 2. Create a Mock Image (32x32 RGB)\n",
        "    # A \"Blurry Dog\" (Low Entropy)\n",
        "    mock_image = np.random.rand(32, 32, 3).astype(np.float32)\n",
        "\n",
        "    # 3. Run the Process\n",
        "    output = vision_mod.process_image(mock_image)\n",
        "\n",
        "    print(\"Vision Module Output Shape:\", output.shape)\n",
        "    print(\"Cycle Complete: Metadata -> Lens -> Stream -> Classification\")"
      ],
      "metadata": {
        "id": "_z1DAxgSUT4S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7db56a44-e1a3-40c0-fa98-1261fc87835c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vision Module Output Shape: (65, 128)\n",
            "Cycle Complete: Metadata -> Lens -> Stream -> Classification\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# ============================================================\n",
        "# PART 1: THE V9.2 PHYSICS ENGINE (PyTorch Edition)\n",
        "# ============================================================\n",
        "\n",
        "class CylindricalRoPE(nn.Module):\n",
        "    \"\"\"\n",
        "    [V9.2] Hierarchical Rotary Embeddings (Day/Hour).\n",
        "    \"\"\"\n",
        "    def __init__(self, dim, day_length=64): # Reduced day_length for CIFAR patches\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.day_length = day_length\n",
        "\n",
        "        # Precompute frequencies (Hour = High Freq, Day = Low Freq)\n",
        "        self.register_buffer('inv_freq_h', 1.0 / (10000 ** (torch.arange(0, dim, 2).float() / dim)))\n",
        "        self.register_buffer('inv_freq_d', 1.0 / (100000 ** (torch.arange(0, dim, 2).float() / dim)))\n",
        "\n",
        "    def forward(self, x, start_index=0):\n",
        "        # x: (Batch, Seq, Dim)\n",
        "        b, seq, dim = x.shape\n",
        "        device = x.device\n",
        "\n",
        "        # 1. Create Linear Indices\n",
        "        indices = torch.arange(start_index, start_index + seq, device=device).float()\n",
        "\n",
        "        # 2. Cylindrical Decomposition\n",
        "        days = indices // self.day_length\n",
        "        hours = indices % self.day_length\n",
        "\n",
        "        # 3. Compute Angles\n",
        "        angles_h = torch.outer(hours, self.inv_freq_h)\n",
        "        angles_d = torch.outer(days, self.inv_freq_d)\n",
        "        total_angle = angles_h + angles_d # The Spiral\n",
        "\n",
        "        # 4. Apply Rotation (cos/sin)\n",
        "        # Repeat for real/imaginary parts\n",
        "        theta = torch.repeat_interleave(total_angle, 2, dim=1)\n",
        "\n",
        "        # Reshape for broadcasting: (1, Seq, Dim)\n",
        "        theta = theta.unsqueeze(0)\n",
        "\n",
        "        cos_t = torch.cos(theta)\n",
        "        sin_t = torch.sin(theta)\n",
        "\n",
        "        x_rot = torch.zeros_like(x)\n",
        "        x_rot[..., 0::2] = x[..., 0::2] * cos_t[..., 0::2] - x[..., 1::2] * sin_t[..., 0::2]\n",
        "        x_rot[..., 1::2] = x[..., 0::2] * sin_t[..., 0::2] + x[..., 1::2] * cos_t[..., 0::2]\n",
        "\n",
        "        return x_rot\n",
        "\n",
        "class LearnablePhi(nn.Module):\n",
        "    \"\"\"\n",
        "    [V9.2] Continuous Normalization Manifold.\n",
        "    Learns to be Linear, Softmax, or Gating.\n",
        "    \"\"\"\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.scale = nn.Parameter(torch.ones(1))\n",
        "        self.shift = nn.Parameter(torch.zeros(1))\n",
        "        self.temperature = nn.Parameter(torch.tensor(1.0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x_affine = (x * self.scale) + self.shift\n",
        "        # For stability in training, we use a simpler Softmax-like gate first\n",
        "        # Ideally this is a spline, effectively a learnable temperature Softmax here\n",
        "        return F.softmax(x * self.temperature, dim=-1)\n",
        "\n",
        "class Atom(nn.Module):\n",
        "    \"\"\"\n",
        "    [V9.2] The Computational Leaf.\n",
        "    Active (Q) vs Passive (K/V) Initialization.\n",
        "    \"\"\"\n",
        "    def __init__(self, dim, init_mode='identity'):\n",
        "        super().__init__()\n",
        "        self.rope = CylindricalRoPE(dim)\n",
        "\n",
        "        # Projection Weights\n",
        "        self.proj = nn.Linear(dim, dim, bias=False)\n",
        "\n",
        "        # Initialization Logic\n",
        "        if init_mode == 'identity':\n",
        "            nn.init.eye_(self.proj.weight)\n",
        "            # Freeze identity layers to preserve signal initially (optional, but good for stability)\n",
        "            # self.proj.weight.requires_grad = False\n",
        "        elif init_mode == 'random':\n",
        "            nn.init.orthogonal_(self.proj.weight, gain=0.1)\n",
        "\n",
        "    def forward(self, x, offset=0):\n",
        "        # 1. RoPE\n",
        "        x = self.rope(x, start_index=offset)\n",
        "        # 2. Project\n",
        "        return self.proj(x)\n",
        "\n",
        "class MixingNode(nn.Module):\n",
        "    \"\"\"\n",
        "    [V9.2] The Recursive Pipe (Sequence Reduction).\n",
        "    \"\"\"\n",
        "    def __init__(self, children_dims, hidden_dim):\n",
        "        super().__init__()\n",
        "        # In a dynamic tree, children are objects.\n",
        "        # Here we hardcode the logic for [Q, K, V] pipe for efficiency.\n",
        "\n",
        "        self.phi = LearnablePhi(hidden_dim)\n",
        "        self.layer_norm = nn.LayerNorm(hidden_dim) # Stabilizer\n",
        "\n",
        "    def forward(self, q, k, v):\n",
        "        # Q, K, V are vectors from Atoms\n",
        "        # q: (B, Seq, Dim), k: (B, Seq, Dim), v: (B, Seq, Dim)\n",
        "\n",
        "        # 1. Interaction A: Q @ K.T -> Attention Map\n",
        "        # (B, S, D) @ (B, D, S) -> (B, S, S)\n",
        "        affinity = torch.matmul(q, k.transpose(-2, -1))\n",
        "\n",
        "        # 2. Continuous Normalization (Phi)\n",
        "        # \"Is it Softmax? Is it Linear?\" The model decides.\n",
        "        weights = self.phi(affinity)\n",
        "\n",
        "        # 3. Interaction B: Weights @ V -> Output\n",
        "        # (B, S, S) @ (B, S, D) -> (B, S, D)\n",
        "        out = torch.matmul(weights, v)\n",
        "\n",
        "        return self.layer_norm(out + q) # Residual connection for gradient flow\n",
        "\n",
        "# ============================================================\n",
        "# PART 2: THE VISION MODULE (Context -> State -> Service)\n",
        "# ============================================================\n",
        "\n",
        "class VisionModule(nn.Module):\n",
        "    def __init__(self, dim=64, patch_size=4, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "        # 1. Embeddings (The \"Retina\")\n",
        "        self.patch_embed = nn.Linear(3 * patch_size * patch_size, dim)\n",
        "        self.lens_embed = nn.Linear(4, dim) # Metadata: [Scale, Entropy, Mean, Bias]\n",
        "\n",
        "        # 2. Context Core (The Lens)\n",
        "        # Simple processing of metadata\n",
        "        self.context_core = nn.Sequential(\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(dim, dim)\n",
        "        )\n",
        "\n",
        "        # 3. State Core (The Eye)\n",
        "        # The V9.2 Recursive Pipe: [[Q, K], V]\n",
        "        # We need Atoms for Q, K, V\n",
        "        self.atom_q = Atom(dim, init_mode='random')   # Active Query\n",
        "        self.atom_k = Atom(dim, init_mode='identity') # Passive Key\n",
        "        self.atom_v = Atom(dim, init_mode='identity') # Passive Value\n",
        "\n",
        "        # The Mixer\n",
        "        self.mixer = MixingNode(dim, dim)\n",
        "\n",
        "        # 4. Service Core (The Labeler)\n",
        "        self.head = nn.Linear(dim, num_classes)\n",
        "\n",
        "    def get_z_order_indices(self, H, W):\n",
        "        # Generates Morton Codes for the grid\n",
        "        # Simple Python implementation for demonstration\n",
        "        # Returns a sorting permutation\n",
        "        indices = []\n",
        "        for y in range(H):\n",
        "            for x in range(W):\n",
        "                # Interleave bits (simplified Z-curve for square grids)\n",
        "                # This is a mock 'worm' for speed, real implementation uses bit-interleaving\n",
        "                indices.append((y, x))\n",
        "        return torch.arange(H*W) # Placeholder: In real training, pre-compute Morton codes\n",
        "\n",
        "    def forward(self, img):\n",
        "        B, C, H, W = img.shape\n",
        "\n",
        "        # --- A. Interface (Linearization) ---\n",
        "        # 1. Metadata extraction\n",
        "        mean = img.mean(dim=(1, 2, 3), keepdim=True)\n",
        "        std = img.std(dim=(1, 2, 3), keepdim=True)\n",
        "        scale = (H * W) / (32 * 32)\n",
        "        meta = torch.cat([torch.tensor(scale).expand(B, 1).to(img.device),\n",
        "                          std.squeeze().unsqueeze(1),\n",
        "                          mean.squeeze().unsqueeze(1),\n",
        "                          torch.ones(B, 1).to(img.device)], dim=1)\n",
        "\n",
        "        # 2. Patchify\n",
        "        # (B, C, H, W) -> (B, N, Patch_Dim)\n",
        "        x = F.unfold(img, kernel_size=self.patch_size, stride=self.patch_size)\n",
        "        x = x.transpose(1, 2) # (B, NumPatches, FlattenedPatch)\n",
        "\n",
        "        # 3. Embed\n",
        "        stream = self.patch_embed(x) # (B, 64, Dim)\n",
        "        lens_in = self.lens_embed(meta).unsqueeze(1) # (B, 1, Dim)\n",
        "\n",
        "        # --- B. Cycle (Context -> State) ---\n",
        "\n",
        "        # 1. Context Core\n",
        "        lens_vector = self.context_core(lens_in) # \"How to look\"\n",
        "\n",
        "        # 2. State Core\n",
        "        # The Stream is [Lens, Patches...]\n",
        "        # Lens is index 0 (Day 0, Hour 0)\n",
        "        # Patches are index 1..N\n",
        "\n",
        "        # Apply Atoms (Recursive Leaves)\n",
        "        # We use the Lens as Q for everything, and Stream as K/V\n",
        "        # This forces the model to look at the image *through* the lens\n",
        "\n",
        "        # Q: The Lens Vector (Instruction)\n",
        "        q = self.atom_q(lens_vector, offset=0)\n",
        "\n",
        "        # K, V: The Image Stream\n",
        "        k = self.atom_k(stream, offset=1)\n",
        "        v = self.atom_v(stream, offset=1)\n",
        "\n",
        "        # Mixing Node (The Pipe)\n",
        "        # Note: We broadcast Q (1 token) across K (64 tokens)\n",
        "        final_state = self.mixer(q, k, v) # (B, 1, Dim)\n",
        "\n",
        "        # --- C. Service Core ---\n",
        "        logits = self.head(final_state.squeeze(1))\n",
        "        return logits\n",
        "\n",
        "# ============================================================\n",
        "# PART 3: THE GYM (Training Loop)\n",
        "# ============================================================\n",
        "\n",
        "def train():\n",
        "    print(\"--- Initializing V9.2 Vision System ---\")\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Device: {device}\")\n",
        "\n",
        "    # Hyperparameters\n",
        "    BATCH_SIZE = 64\n",
        "    EPOCHS = 5\n",
        "    LR = 0.001\n",
        "\n",
        "    # Data (CIFAR-10)\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    print(\"Downloading CIFAR-10...\")\n",
        "    train_set = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    # Model\n",
        "    model = VisionModule(dim=128, patch_size=4, num_classes=10).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    print(\"--- Starting Training Cycle ---\")\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for i, (imgs, labels) in enumerate(train_loader):\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward (Context -> State -> Service)\n",
        "            outputs = model(imgs)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                print(f\"Epoch [{epoch+1}/{EPOCHS}], Step [{i}/{len(train_loader)}], Loss: {loss.item():.4f}, Acc: {100.*correct/total:.2f}%\")\n",
        "\n",
        "        print(f\"=== Epoch {epoch+1} Complete. Avg Loss: {total_loss/len(train_loader):.4f} ===\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D8uYNFg8kVv",
        "outputId": "83657df4-626a-4036-be62-f1bb11ec5e57"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Initializing V9.2 Vision System ---\n",
            "Device: cpu\n",
            "Downloading CIFAR-10...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:02<00:00, 58.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Training Cycle ---\n",
            "Epoch [1/5], Step [0/782], Loss: 2.6168, Acc: 4.69%\n",
            "Epoch [1/5], Step [100/782], Loss: 1.9288, Acc: 28.30%\n",
            "Epoch [1/5], Step [200/782], Loss: 1.7893, Acc: 31.31%\n",
            "Epoch [1/5], Step [300/782], Loss: 1.7642, Acc: 32.58%\n",
            "Epoch [1/5], Step [400/782], Loss: 1.6993, Acc: 33.73%\n",
            "Epoch [1/5], Step [500/782], Loss: 1.7156, Acc: 34.69%\n",
            "Epoch [1/5], Step [600/782], Loss: 1.6982, Acc: 35.21%\n",
            "Epoch [1/5], Step [700/782], Loss: 1.4660, Acc: 35.89%\n",
            "=== Epoch 1 Complete. Avg Loss: 1.7649 ===\n",
            "Epoch [2/5], Step [0/782], Loss: 1.8042, Acc: 39.06%\n",
            "Epoch [2/5], Step [100/782], Loss: 1.5607, Acc: 40.73%\n",
            "Epoch [2/5], Step [200/782], Loss: 1.6113, Acc: 40.54%\n",
            "Epoch [2/5], Step [300/782], Loss: 1.5068, Acc: 41.02%\n",
            "Epoch [2/5], Step [400/782], Loss: 1.6581, Acc: 41.04%\n",
            "Epoch [2/5], Step [500/782], Loss: 1.8348, Acc: 40.90%\n",
            "Epoch [2/5], Step [600/782], Loss: 1.4814, Acc: 40.92%\n",
            "Epoch [2/5], Step [700/782], Loss: 1.3160, Acc: 41.19%\n",
            "=== Epoch 2 Complete. Avg Loss: 1.6286 ===\n",
            "Epoch [3/5], Step [0/782], Loss: 1.6399, Acc: 39.06%\n",
            "Epoch [3/5], Step [100/782], Loss: 1.5842, Acc: 41.86%\n",
            "Epoch [3/5], Step [200/782], Loss: 1.3225, Acc: 42.51%\n",
            "Epoch [3/5], Step [300/782], Loss: 1.5709, Acc: 42.84%\n",
            "Epoch [3/5], Step [400/782], Loss: 1.6815, Acc: 43.01%\n",
            "Epoch [3/5], Step [500/782], Loss: 1.6171, Acc: 43.06%\n",
            "Epoch [3/5], Step [600/782], Loss: 1.7747, Acc: 43.02%\n",
            "Epoch [3/5], Step [700/782], Loss: 1.5332, Acc: 42.96%\n",
            "=== Epoch 3 Complete. Avg Loss: 1.5892 ===\n",
            "Epoch [4/5], Step [0/782], Loss: 1.7006, Acc: 50.00%\n",
            "Epoch [4/5], Step [100/782], Loss: 1.6186, Acc: 42.65%\n",
            "Epoch [4/5], Step [200/782], Loss: 1.4835, Acc: 43.41%\n",
            "Epoch [4/5], Step [300/782], Loss: 1.7070, Acc: 43.63%\n",
            "Epoch [4/5], Step [400/782], Loss: 1.6707, Acc: 43.56%\n",
            "Epoch [4/5], Step [500/782], Loss: 1.6130, Acc: 43.46%\n",
            "Epoch [4/5], Step [600/782], Loss: 1.7053, Acc: 43.33%\n",
            "Epoch [4/5], Step [700/782], Loss: 1.7397, Acc: 43.33%\n",
            "=== Epoch 4 Complete. Avg Loss: 1.5702 ===\n",
            "Epoch [5/5], Step [0/782], Loss: 1.6644, Acc: 39.06%\n",
            "Epoch [5/5], Step [100/782], Loss: 1.5312, Acc: 43.15%\n",
            "Epoch [5/5], Step [200/782], Loss: 1.4741, Acc: 43.79%\n",
            "Epoch [5/5], Step [300/782], Loss: 1.5281, Acc: 43.45%\n",
            "Epoch [5/5], Step [400/782], Loss: 1.6358, Acc: 43.65%\n",
            "Epoch [5/5], Step [500/782], Loss: 1.4047, Acc: 43.74%\n",
            "Epoch [5/5], Step [600/782], Loss: 1.6558, Acc: 43.98%\n",
            "Epoch [5/5], Step [700/782], Loss: 1.5050, Acc: 44.00%\n",
            "=== Epoch 5 Complete. Avg Loss: 1.5544 ===\n"
          ]
        }
      ]
    }
  ]
}
